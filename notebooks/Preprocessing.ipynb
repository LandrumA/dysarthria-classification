{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f4ea85-6f20-437b-8273-143f17723107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning for max audio length...\n",
      "‚úÖ Max length found: 0 samples\n",
      "üöÄ Starting normalization...\n",
      "üéâ All files normalized and saved!\n"
     ]
    }
   ],
   "source": [
    "##NDDS preprocess\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "import numpy as np\n",
    "\n",
    "# ==============================\n",
    "# üîß Set your input/output paths\n",
    "# ==============================\n",
    "input_dir = \"/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/dysarthria_raw/dysarthria_raw_single-words/NDDS-single-words/\"\n",
    "output_dir = \"/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/output\"\n",
    "\n",
    "# ==============================\n",
    "# Step 1: Get Maximum Audio Length\n",
    "# ==============================\n",
    "def get_max_audio_length(audio_dir):\n",
    "    max_length = 0\n",
    "    print(\"üîç Scanning for max audio length...\")\n",
    "    for root, _, files in os.walk(audio_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    y, sr = librosa.load(filepath, sr=None)\n",
    "                    max_length = max(max_length, len(y))\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] Could not process {filepath}: {e}\")\n",
    "    print(f\"‚úÖ Max length found: {max_length} samples\")\n",
    "    return max_length\n",
    "\n",
    "# ==============================\n",
    "# Step 2: Normalize + Denoise + Pad\n",
    "# ==============================\n",
    "def normalize_and_pad_audio(filepath, max_len, output_path):\n",
    "    try:\n",
    "        # Load and reduce noise\n",
    "        y, sr = librosa.load(filepath, sr=None)\n",
    "        y_denoised = nr.reduce_noise(y=y, sr=sr)\n",
    "\n",
    "        # Save to temporary WAV file for PyDub to process\n",
    "        temp_path = \"temp_denoised.wav\"\n",
    "        wav_write(temp_path, sr, (y_denoised * 32767).astype(np.int16))\n",
    "\n",
    "        # Normalize volume with PyDub\n",
    "        audio = AudioSegment.from_wav(temp_path)\n",
    "        normalized_audio = audio.apply_gain(-audio.max_dBFS)\n",
    "\n",
    "        # Convert back to numpy\n",
    "        samples = np.array(normalized_audio.get_array_of_samples()).astype(np.float32)\n",
    "        if np.max(np.abs(samples)) != 0:\n",
    "            samples /= np.max(np.abs(samples))  # Normalize to [-1, 1]\n",
    "\n",
    "        # Pad\n",
    "        if len(samples) < max_len:\n",
    "            samples = np.pad(samples, (0, max_len - len(samples)), mode='constant')\n",
    "\n",
    "        # Save to output\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        wav_write(output_path, sr, (samples * 32767).astype(np.int16))\n",
    "\n",
    "        # Cleanup\n",
    "        os.remove(temp_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to normalize {filepath}: {e}\")\n",
    "\n",
    "# ==============================\n",
    "# Step 3: Normalize Entire Dataset\n",
    "# ==============================\n",
    "def normalize_dataset(input_dir, output_dir):\n",
    "    max_len = get_max_audio_length(input_dir)\n",
    "    print(\"üöÄ Starting normalization...\")\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith(\".wav\"):\n",
    "                rel_path = os.path.relpath(root, input_dir)\n",
    "                input_path = os.path.join(root, file)\n",
    "                output_path = os.path.join(output_dir, rel_path, file)\n",
    "\n",
    "                print(f\"‚Üí Processing: {input_path}\")\n",
    "                normalize_and_pad_audio(input_path, max_len, output_path)\n",
    "\n",
    "    print(\"üéâ All files normalized and saved!\")\n",
    "\n",
    "# ==============================\n",
    "# ‚úÖ Run It\n",
    "# ==============================\n",
    "normalize_dataset(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c9b1e7b-3c16-4e55-9d76-de0a2bee58f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (0.11.0)\n",
      "Requirement already satisfied: noisereduce in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (3.0.3)\n",
      "Requirement already satisfied: pydub in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (0.25.1)\n",
      "Requirement already satisfied: scipy in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (4.11.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from librosa) (1.0.3)\n",
      "Requirement already satisfied: matplotlib in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from noisereduce) (3.9.2)\n",
      "Requirement already satisfied: tqdm in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from noisereduce) (4.66.5)\n",
      "Requirement already satisfied: packaging in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (3.10.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->librosa) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from matplotlib->noisereduce) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib->noisereduce) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/the_fat_cat/anaconda3/lib/python3.12/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install librosa noisereduce pydub scipy numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711e08f0-82da-40c8-a5a1-3c73b4bae2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Scanning for maximum audio length...\n",
      " Max length found: 0 samples\n",
      "Starting normalization of dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing WAV Files: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset normalization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "##UASpeech Single Word\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================\n",
    "# Set your input/output paths and configuration\n",
    "# ============================================\n",
    "input_dir = \"/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/dysarthria_raw/dysarthria_raw_single-words/UASpeech-single-words/\"\n",
    "output_dir = \"/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/output/UASpeech_pp/\"\n",
    "\n",
    "# ============================================\n",
    "# Step 1: Get Maximum Audio Length (in samples)\n",
    "# ============================================\n",
    "def get_max_audio_length(audio_dir):\n",
    "    max_length = 0\n",
    "    print(\"üîç Scanning for maximum audio length...\")\n",
    "    for root, _, files in os.walk(audio_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".wav\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    y, sr = librosa.load(filepath, sr=None)\n",
    "                    current_length = len(y)\n",
    "                    if current_length > max_length:\n",
    "                        max_length = current_length\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] Could not process {filepath}: {e}\")\n",
    "    print(f\" Max length found: {max_length} samples\")\n",
    "    return max_length\n",
    "\n",
    "# ============================================\n",
    "# Step 2: Normalize, Denoise, and Pad a single audio file\n",
    "# ============================================\n",
    "def normalize_and_pad_audio(filepath, max_len, output_path):\n",
    "    try:\n",
    "        # Load the audio file using librosa\n",
    "        y, sr = librosa.load(filepath, sr=None)\n",
    "        \n",
    "        # Reduce noise using noisereduce\n",
    "        y_denoised = nr.reduce_noise(y=y, sr=sr)\n",
    "        \n",
    "        # Save to a temporary file (16-bit PCM)\n",
    "        temp_path = \"temp_denoised.wav\"\n",
    "        wav_write(temp_path, sr, (y_denoised * 32767).astype(np.int16))\n",
    "        \n",
    "        # Use PyDub to load the temporary file and normalize volume\n",
    "        audio = AudioSegment.from_wav(temp_path)\n",
    "        normalized_audio = audio.apply_gain(-audio.max_dBFS)\n",
    "        \n",
    "        # Convert the normalized audio back to a NumPy array (float32)\n",
    "        samples = np.array(normalized_audio.get_array_of_samples()).astype(np.float32)\n",
    "        if np.max(np.abs(samples)) != 0:\n",
    "            samples /= np.max(np.abs(samples))  # scale to [-1, 1]\n",
    "        \n",
    "        # Pad the audio if it is shorter than the maximum length\n",
    "        if len(samples) < max_len:\n",
    "            samples = np.pad(samples, (0, max_len - len(samples)), mode='constant')\n",
    "        \n",
    "        # Ensure the output directory exists and save the final WAV file\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        wav_write(output_path, sr, (samples * 32767).astype(np.int16))\n",
    "        \n",
    "        # Cleanup temporary file\n",
    "        os.remove(temp_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to normalize {filepath}: {e}\")\n",
    "\n",
    "# ============================================\n",
    "# Step 3: Process the Entire Dataset with a Progress Bar\n",
    "# ============================================\n",
    "def normalize_dataset(input_dir, output_dir):\n",
    "    max_len = get_max_audio_length(input_dir)\n",
    "    print(\"Starting normalization of dataset...\")\n",
    "\n",
    "    # Build a list of all WAV files (with their relative path info)\n",
    "    file_list = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".wav\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(root, input_dir)\n",
    "                file_list.append((full_path, rel_path, file))\n",
    "    \n",
    "    # Process each file with a progress bar\n",
    "    for input_file, rel_path, file in tqdm(file_list, desc=\"Processing WAV Files\", total=len(file_list)):\n",
    "        output_file = os.path.join(output_dir, rel_path, file)\n",
    "        normalize_and_pad_audio(input_file, max_len, output_file)\n",
    "\n",
    "    print(\"Dataset normalization complete!\")\n",
    "\n",
    "# ============================================\n",
    "# Run the script\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_dataset(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc66d8-c01e-4d98-844e-7f9b0d33718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TORGO Single Word\n",
    "\n",
    "import os\n",
    "import librosa\n",
    "import noisereduce as nr\n",
    "from pydub import AudioSegment\n",
    "from scipy.io.wavfile import write as wav_write\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================\n",
    "# Set your input/output paths and configuration\n",
    "# ============================================\n",
    "input_dir = \"/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/dysarthria_raw/dysarthria_raw_single-words/UASpeech-single-words/\"\n",
    "output_dir = \"/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/output/UASpeech_pp/\"\n",
    "\n",
    "# ============================================\n",
    "# Step 1: Get Maximum Audio Length (in samples)\n",
    "# ============================================\n",
    "def get_max_audio_length(audio_dir):\n",
    "    max_length = 0\n",
    "    print(\"üîç Scanning for maximum audio length...\")\n",
    "    for root, _, files in os.walk(audio_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".wav\"):\n",
    "                filepath = os.path.join(root, file)\n",
    "                try:\n",
    "                    y, sr = librosa.load(filepath, sr=None)\n",
    "                    current_length = len(y)\n",
    "                    if current_length > max_length:\n",
    "                        max_length = current_length\n",
    "                except Exception as e:\n",
    "                    print(f\"[Error] Could not process {filepath}: {e}\")\n",
    "    print(f\" Max length found: {max_length} samples\")\n",
    "    return max_length\n",
    "\n",
    "# ============================================\n",
    "# Step 2: Normalize, Denoise, and Pad a single audio file\n",
    "# ============================================\n",
    "def normalize_and_pad_audio(filepath, max_len, output_path):\n",
    "    try:\n",
    "        # Load the audio file using librosa\n",
    "        y, sr = librosa.load(filepath, sr=None)\n",
    "        \n",
    "        # Reduce noise using noisereduce\n",
    "        y_denoised = nr.reduce_noise(y=y, sr=sr)\n",
    "        \n",
    "        # Save to a temporary file (16-bit PCM)\n",
    "        temp_path = \"temp_denoised.wav\"\n",
    "        wav_write(temp_path, sr, (y_denoised * 32767).astype(np.int16))\n",
    "        \n",
    "        # Use PyDub to load the temporary file and normalize volume\n",
    "        audio = AudioSegment.from_wav(temp_path)\n",
    "        normalized_audio = audio.apply_gain(-audio.max_dBFS)\n",
    "        \n",
    "        # Convert the normalized audio back to a NumPy array (float32)\n",
    "        samples = np.array(normalized_audio.get_array_of_samples()).astype(np.float32)\n",
    "        if np.max(np.abs(samples)) != 0:\n",
    "            samples /= np.max(np.abs(samples))  # scale to [-1, 1]\n",
    "        \n",
    "        # Pad the audio if it is shorter than the maximum length\n",
    "        if len(samples) < max_len:\n",
    "            samples = np.pad(samples, (0, max_len - len(samples)), mode='constant')\n",
    "        \n",
    "        # Ensure the output directory exists and save the final WAV file\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        wav_write(output_path, sr, (samples * 32767).astype(np.int16))\n",
    "        \n",
    "        # Cleanup temporary file\n",
    "        os.remove(temp_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] Failed to normalize {filepath}: {e}\")\n",
    "\n",
    "# ============================================\n",
    "# Step 3: Process the Entire Dataset with a Progress Bar\n",
    "# ============================================\n",
    "def normalize_dataset(input_dir, output_dir):\n",
    "    max_len = get_max_audio_length(input_dir)\n",
    "    print(\"Starting normalization of dataset...\")\n",
    "\n",
    "    # Build a list of all WAV files (with their relative path info)\n",
    "    file_list = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\".wav\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                rel_path = os.path.relpath(root, input_dir)\n",
    "                file_list.append((full_path, rel_path, file))\n",
    "    \n",
    "    # Process each file with a progress bar\n",
    "    for input_file, rel_path, file in tqdm(file_list, desc=\"Processing WAV Files\", total=len(file_list)):\n",
    "        output_file = os.path.join(output_dir, rel_path, file)\n",
    "        normalize_and_pad_audio(input_file, max_len, output_file)\n",
    "\n",
    "    print(\"Dataset normalization complete!\")\n",
    "\n",
    "# ============================================\n",
    "# Run the script\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "    normalize_dataset(input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c795f1c-6687-41ff-9221-b70802c16b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
