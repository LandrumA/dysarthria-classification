{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c581118-5885-4ef1-84c9-eb387cee305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: librosa in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: matplotlib in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (3.10.1)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: numpy in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (0.61.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (1.15.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (5.2.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (4.13.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from numba>=0.51.0->librosa) (0.44.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from pooch>=1.1->librosa) (4.3.7)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/the_fat_cat/anaconda3/envs/mfa-env/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.1.31)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install librosa matplotlib pandas numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2414fa4c-4481-4350-8437-067450929ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete.\n",
      "Metadata saved to: /home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/metadata\n",
      "                 filename database gender speaker_id recording_id      label\n",
      "0     NDDS_m_01_001_a.wav     NDDS      m         01          001  afflicted\n",
      "1     NDDS_m_01_002_a.wav     NDDS      m         01          002  afflicted\n",
      "2     NDDS_m_01_003_a.wav     NDDS      m         01          003  afflicted\n",
      "3     NDDS_m_01_004_a.wav     NDDS      m         01          004  afflicted\n",
      "4     NDDS_m_01_005_a.wav     NDDS      m         01          005  afflicted\n",
      "...                   ...      ...    ...        ...          ...        ...\n",
      "2884  NDDS_m_11_249_a.wav     NDDS      m         11          249  afflicted\n",
      "2885  NDDS_m_11_250_a.wav     NDDS      m         11          250  afflicted\n",
      "2886  NDDS_m_11_251_a.wav     NDDS      m         11          251  afflicted\n",
      "2887  NDDS_m_11_252_a.wav     NDDS      m         11          252  afflicted\n",
      "2888  NDDS_m_11_253_a.wav     NDDS      m         11          253  afflicted\n",
      "\n",
      "[2889 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# ===================== CONFIGURATION =====================\n",
    "INPUT_FOLDER = '/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/output/'  # Folder where .wav files are stored\n",
    "MFCC_OUTPUT_FOLDER = '/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/MFCC'  # Folder to save MFCC CSVs\n",
    "SPECTROGRAM_OUTPUT_FOLDER = '/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/spectrograms'  # Folder to save Mel spectrogram images (PNG)\n",
    "EXAMPLE_PLOTS_FOLDER = '/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/example_plots'  # Folder to save example plots (both MFCC and spectrogram)\n",
    "METADATA_CSV_PATH = '/home/the_fat_cat/Documents/GitHub/dysarthria-classification/data/processed/metadata'  # Master CSV file that will store the metadata\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs(MFCC_OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(SPECTROGRAM_OUTPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(EXAMPLE_PLOTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# ===================== DATA PROCESSING =====================\n",
    "metadata = []  # To store metadata for each file\n",
    "example_candidates = []  # Store candidate data for generating sample plots\n",
    "\n",
    "# Get all .wav files (recursively) from the input folder\n",
    "audio_files = sorted(Path(INPUT_FOLDER).rglob(\"*.wav\"))\n",
    "\n",
    "for file_path in audio_files:\n",
    "    filename = file_path.stem  # Get filename without extension\n",
    "    parts = filename.split('_')\n",
    "    \n",
    "    # Expecting the format: <database>_<gender>_<speaker#>_<recording#>_<a|c>\n",
    "    if len(parts) != 5:\n",
    "        print(f\"Skipping {file_path.name} due to unexpected filename format.\")\n",
    "        continue\n",
    "    \n",
    "    database, gender, speaker, recording, label_code = parts\n",
    "    # Determine label based on the last part of filename\n",
    "    if label_code == 'a':\n",
    "        label = 'afflicted'\n",
    "    elif label_code == 'c':\n",
    "        label = 'control'\n",
    "    else:\n",
    "        print(f\"Skipping {file_path.name} due to unknown label code '{label_code}'.\")\n",
    "        continue\n",
    "    \n",
    "    # Load the audio file (assuming fixed length per your project)\n",
    "    y, sr = librosa.load(file_path, sr=None)\n",
    "    \n",
    "    # ---- MFCC Extraction ----\n",
    "    # Extract 13 MFCC coefficients (each column represents a frame)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    mfcc_df = pd.DataFrame(mfcc)\n",
    "    \n",
    "    # Save the MFCCs as a CSV file (the CSV filename mirrors the audio filename)\n",
    "    mfcc_csv_filename = f\"{filename}.csv\"\n",
    "    mfcc_csv_full_path = os.path.join(MFCC_OUTPUT_FOLDER, mfcc_csv_filename)\n",
    "    mfcc_df.to_csv(mfcc_csv_full_path, index=False)\n",
    "    \n",
    "    # ---- Mel Spectrogram Generation ----\n",
    "    # Compute the Mel spectrogram and convert to decibel units\n",
    "    S = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=512)\n",
    "    S_dB = librosa.power_to_db(S, ref=np.max)\n",
    "    \n",
    "    # Save Mel spectrogram to disk as a PNG image\n",
    "    spec_img_filename = f\"{filename}.png\"\n",
    "    spec_img_full_path = os.path.join(SPECTROGRAM_OUTPUT_FOLDER, spec_img_filename)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Mel Spectrogram: {filename}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(spec_img_full_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # ---- Metadata Collection ----\n",
    "    metadata.append({\n",
    "        \"filename\": f\"{filename}.wav\",\n",
    "        \"database\": database,\n",
    "        \"gender\": gender,\n",
    "        \"speaker_id\": speaker,\n",
    "        \"recording_id\": recording,\n",
    "        \"label\": label\n",
    "    })\n",
    "    \n",
    "    # Save data for candidate examples (to generate example plots later)\n",
    "    example_candidates.append({\n",
    "        \"filename\": filename,\n",
    "        \"mfcc\": mfcc,\n",
    "        \"spectrogram\": S_dB,\n",
    "        \"sr\": sr\n",
    "    })\n",
    "\n",
    "# ===================== SAVE METADATA =====================\n",
    "# Create a master metadata CSV file that contains details for every processed file.\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "metadata_df.to_csv(METADATA_CSV_PATH, index=False)\n",
    "\n",
    "# ===================== GENERATE EXAMPLE PLOTS =====================\n",
    "# Select 3 random examples (or all available if less than 3 exist)\n",
    "if len(example_candidates) >= 3:\n",
    "    selected_examples = random.sample(example_candidates, 3)\n",
    "else:\n",
    "    selected_examples = example_candidates\n",
    "\n",
    "for example in selected_examples:\n",
    "    file_base = example[\"filename\"]\n",
    "    mfcc = example[\"mfcc\"]\n",
    "    spectrogram = example[\"spectrogram\"]\n",
    "    sr = example[\"sr\"]\n",
    "    \n",
    "    # ---- MFCC Example Plot ----\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(mfcc, x_axis='time')\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"MFCC (13 coefficients): {file_base}\")\n",
    "    plt.tight_layout()\n",
    "    mfcc_example_path = os.path.join(EXAMPLE_PLOTS_FOLDER, f\"{file_base}_mfcc_example.png\")\n",
    "    plt.savefig(mfcc_example_path)\n",
    "    plt.close()\n",
    "    \n",
    "    # ---- Mel Spectrogram Example Plot ----\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    librosa.display.specshow(spectrogram, sr=sr, x_axis='time', y_axis='mel')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(f\"Mel Spectrogram: {file_base}\")\n",
    "    plt.tight_layout()\n",
    "    spec_example_path = os.path.join(EXAMPLE_PLOTS_FOLDER, f\"{file_base}_spectrogram_example.png\")\n",
    "    plt.savefig(spec_example_path)\n",
    "    plt.close()\n",
    "\n",
    "print(\"Processing complete.\")\n",
    "print(f\"Metadata saved to: {METADATA_CSV_PATH}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    import ace_tools\n",
    "    ace_tools.display_dataframe_to_user(name=\"Metadata\", dataframe=metadata_df)\n",
    "except ImportError:\n",
    "    print(metadata_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3d06d6-e660-4d25-89f5-bbb28c4aaafc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mfa-env)",
   "language": "python",
   "name": "mfa-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
